lr: 0.0005
gamma: 0.99
lmbda: 0.95
clip_ratio: 0.2
value_coef: 0.5
entropy_coef: 0.0
total_time_steps: 1000_000_000
num_steps: 32
num_mini_batches: 5
num_envs: 4096
num_epochs: 4
max_grad_norm: 1.0
normalize_advantages: True
normalize_env: True
anneal_lr: True
num_eval: 1
max_episode_steps: 5000
hidden_dim: 512
use_tanh_gaussian: False
loss: ppo



network:
  _target_: src.algorithms.ppo.networks.PPONetworks
  _partial_: true
init:
  _target_: src.algorithms.ppo.ff_ppo.make_init_fn
  _partial_: true
learner:
  _target_: src.algorithms.ppo.ff_ppo.make_learner_fn
  _partial_: true
policy:
  _target_: src.algorithms.ppo.ff_ppo.make_policy_fn
  _partial_: true
